{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBS0rIyembad"
      },
      "outputs": [],
      "source": [
        "!pip install sentencepiece\n",
        "!pip install tokenizers\n",
        "!pip install transformers\n",
        "\n",
        "import json\n",
        "import urllib\n",
        "import torch.nn as nn\n",
        "import json\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import transformers\n",
        "from transformers import  BertForTokenClassification , BertTokenizer, BertForPreTraining, BertConfig, AdamW \n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "# from timeit import default_timer as timer\n",
        "\n",
        "import string \n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset , DataLoader\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlLX-k-omnDK"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExeavrU09Cvs"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS=15\n",
        "accumulation_steps=4\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "MODEL_NAME='bert-base-cased'\n",
        "tokenizer=BertTokenizer.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojJE0kTsoan9"
      },
      "outputs": [],
      "source": [
        "#DOWLOAND  TRAINING DATASET\n",
        "\n",
        "# load dataset\n",
        "url='https://raw.githubusercontent.com/MikeDoes/ETH_NLP_Project/main/fin_num_5_train.json'\n",
        "response = urllib.request.urlopen(url)\n",
        "unprocessed_traindataset=json.loads(response.read()) \n",
        "\n",
        "with open('/content/train_dataset.json', 'w') as f:\n",
        "  json.dump(unprocessed_traindataset, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68a4SFD9mBUE"
      },
      "outputs": [],
      "source": [
        "#DOWLOAND AND VALIDATION DATASET\n",
        "\n",
        "url='https://raw.githubusercontent.com/MikeDoes/ETH_NLP_Project/main/fin_num_5_validate.json'\n",
        "response = urllib.request.urlopen(url)\n",
        "unprocessed_valdataset=json.loads(response.read())\n",
        "#todo: check with Michael the split. 285 +40 != 409  \n",
        "\n",
        "with open('/content/validate_dataset.json', 'w') as f:\n",
        "    json.dump(unprocessed_valdataset, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mX8lsrMuHbIk"
      },
      "outputs": [],
      "source": [
        "# DOWNLOAD TESTDATASET\n",
        "\n",
        "url='https://raw.githubusercontent.com/MikeDoes/ETH_NLP_Project/main/fin_num_5_test.json'\n",
        "response = urllib.request.urlopen(url)\n",
        "unprocessed_test=json.loads(response.read())\n",
        "\n",
        "\n",
        "with open('/content/test_dataset.json', 'w') as f:\n",
        "  json.dump(unprocessed_test, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxdvnuF-HV5t"
      },
      "outputs": [],
      "source": [
        "def clean(par):\n",
        "    \"\"\"\n",
        "    args: str\n",
        "    receives a paragraph and cleans its text\n",
        "    example: data_rows.iloc[0,0]    \n",
        "    \"\"\"\n",
        "    par\n",
        "    par = par.lower() #remove capital letters\n",
        "    par = par.replace(\"[^a-zA-Z]\", \" \") #remove non english characters\n",
        "    # remove pontuation, as the punctuation i also converted into tokens\n",
        "    for char in par:\n",
        "        if char in string.punctuation:\n",
        "            par = par.replace(char,\"\")\n",
        "    return par"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UJb3WNXH_8R"
      },
      "outputs": [],
      "source": [
        "def categories_list(data):\n",
        "  \"\"\n",
        "  \"receives the data and returns all the labels found\"\n",
        "  \"\"\n",
        "  labels =[0]\n",
        "  for i in range(len(data)):\n",
        "      numbers = data[i][\"entities\"]\n",
        "      for j in range(len(numbers)):\n",
        "        category = numbers[j][\"category\"]\n",
        "        labels.append(category)\n",
        "\n",
        "  labels_uniq = list(set(labels)) #todo: check before 0 is a token for padding, so probably we can t add as 0 \n",
        "    \n",
        "  return labels_uniq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6y-NEFyuLkvc"
      },
      "outputs": [],
      "source": [
        "labels_list = categories_list(unprocessed_traindataset)\n",
        "LABELS_LIST = categories_list(unprocessed_traindataset) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDR0YUwXGcee"
      },
      "outputs": [],
      "source": [
        "def build_label(par,target,categories,tokenizer=tokenizer):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "      par: paragraph (original paragraph so we can calculate the position \n",
        "      targets: format [{'number': '80', 'label': 'percentage', 'pos': 373}]\n",
        "      categories: full list of categories\n",
        "    Outputs: a vector of the same size as the tokenized paragraph, with 0s and the label in the word positioning\n",
        "  \"\"\"\n",
        "  #clean the paragraph\n",
        "  par_clean=clean(par)\n",
        "  par_token=tokenizer(par_clean)[\"input_ids\"]\n",
        "  \n",
        "  #initiates a vector with the same size as the tokenized paragraph\n",
        "  y_vector = np.zeros(len(par_token)) \n",
        "  \n",
        "  #if the y (target) has still the original categories and not tokenized\n",
        "  for i in range(len(target)):\n",
        "    \n",
        "    pos_start=target[i][\"offset_start\"] #get the position of the number\n",
        "    pos_end=target[i][\"offset_end\"] #get the position of the number\n",
        "    \n",
        "    spl_start = par[0:pos_start+1] #split the original paragraph untill position of wanted number (+1 as the position starts in 1)\n",
        "    spl_end = par[0:pos_end+1] #split the original paragraph untill position of wanted number\n",
        "\n",
        "    spl_clean_start = clean(spl_start) #now we clean the splitted paragraph\n",
        "    spl_clean_end = clean(spl_end) #now we clean the splitted paragraph\n",
        "    \n",
        "    # tokenize the splitted and clean paragraph and calculate the length of the tokenized vector\n",
        "    spl_token_start = tokenizer(spl_clean_start,return_tensors='pt')[\"input_ids\"]\n",
        "    spl_token_end = tokenizer(spl_clean_end,return_tensors='pt')[\"input_ids\"]\n",
        "\n",
        "    size_start = len(spl_token_start[0])-2 #-1 to remove token=102 which is the end of the vector -1 because lengths does not count with 0\n",
        "    size_end = len(spl_token_end[0])-2 #-1 to remove token=102 which is the end of the vector -1 because lengths does not count with 0\n",
        "\n",
        "    diff = size_end - size_start + 1\n",
        "    pos = size_start\n",
        "\n",
        "    #in the equivalent position of the number found, we add the category label, which is given by the position in the list\n",
        "    if diff == 1:\n",
        "      y_vector[pos] = np.where(np.array(categories)==target[i][\"category\"])[0][0]\n",
        "    else:\n",
        "      pos=size_start\n",
        "      for k in range(diff):\n",
        "        # print('k',k,'pos',pos)\n",
        "        y_vector[pos] = np.where(np.array(categories)==target[i][\"category\"])[0][0]\n",
        "        pos =pos+1\n",
        "   \n",
        "  y_vector=torch.from_numpy(y_vector)\n",
        "  y_vector=y_vector.type(torch.LongTensor)\n",
        "     \n",
        "  return y_vector#todo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Evnvly9nzKpg"
      },
      "outputs": [],
      "source": [
        "def recognise_numbers(par,tokenizer = tokenizer):\n",
        "  \"\"\"\"\n",
        "  arg: paragraph, string format\n",
        "  returns: tensor of size of the tokenized paragraph with 1s where the token numbers are\n",
        "  deterministic way\n",
        "  \"\"\"\n",
        "  \n",
        "  par_clean=clean(par)\n",
        "  par_token=tokenizer(par_clean)[\"input_ids\"]\n",
        "  recognise_numbers = np.zeros(len(par_token))\n",
        "  pos = 0\n",
        "  for char in par:\n",
        "    if char.isdigit() == True:\n",
        "      spl = par[0:pos+1]\n",
        "      spl_clean = clean(spl)\n",
        "      spl_token = tokenizer(spl_clean,return_tensors='pt')[\"input_ids\"]\n",
        "      size = len(spl_token[0])-2\n",
        "      recognise_numbers[size] = 1\n",
        "    pos =pos+1\n",
        "  \n",
        "  recognise_numbers=torch.from_numpy(recognise_numbers)\n",
        "  recognise_numbers=recognise_numbers.type(torch.LongTensor)\n",
        "  \n",
        "  return recognise_numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucFy4Q8VodTN",
        "outputId": "68668451-586b-4190-eb45-c0dd3ac02af4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "###BUILDING PD DATAFRAME\n",
        "\n",
        "def extract_list( path_1 : Path):\n",
        "  with path_1.open() as json_file:\n",
        "    data=json.load(json_file)\n",
        "\n",
        "  labels_list=categories_list(data)\n",
        "  data_rows=[]\n",
        "  i=0\n",
        "  for element in data:\n",
        "    i+=1\n",
        "    paragraph=clean(element['paragraph'])\n",
        "    target=build_label( element['paragraph'] , element['entities'] , labels_list ) #TODO : GLOBAL LABEL LIST\n",
        "\n",
        "    data_rows.append({\n",
        "        'input' : paragraph ,\n",
        "        'target' : target  ,\n",
        "        'original' : element['paragraph']  ,\n",
        "        'positions' : element['entities']  ,\n",
        "    })\n",
        "\n",
        "\n",
        "  return data_rows\n",
        "      \n",
        "\n",
        "train_list=extract_list(Path(\"/content/train_dataset.json\"))\n",
        "validate_list=extract_list(Path(\"/content/validate_dataset.json\"))\n",
        "test_list=extract_list(Path(\"/content/test_dataset.json\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqfn4t0fQiHH"
      },
      "outputs": [],
      "source": [
        "class NERDataset(Dataset):\n",
        "  def __init__(\n",
        "      self,\n",
        "      data: list,\n",
        "      tokenizer: BertTokenizer,\n",
        "  ):\n",
        "      self.tokenizer=tokenizer,\n",
        "      self.data=data\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self,index:int):\n",
        "\n",
        "    ##DATA ROW\n",
        "    data_row=self.data[index]\n",
        "\n",
        "\n",
        "    ##SOURCE ENCODING\n",
        "    source_encoding=tokenizer(\n",
        "    data_row['input'],\n",
        "    return_tensors=\"pt\",\n",
        "    max_length=512,\n",
        "    truncation=True)\n",
        "\n",
        "    labels=data_row[\"target\"]\n",
        "    index_mask=recognise_numbers(data_row['original'])\n",
        "    \n",
        "    labels=labels[0:512]\n",
        "    index_mask=index_mask[0:512]\n",
        "\n",
        "    return dict(\n",
        "        input_ids=source_encoding[\"input_ids\"],\n",
        "        labels=labels,\n",
        "        index_mask=index_mask\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZkIAoM1RjPM"
      },
      "outputs": [],
      "source": [
        "class NERmodel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model = BertForTokenClassification.from_pretrained('bert-base-uncased',problem_type=\"multi_label_classification\").to(device)\n",
        "    self.model.config.num_labels=10\n",
        "    self.model.classifier = nn.Linear(in_features=768, out_features=10, bias=False)\n",
        "    self.softmax_layer=nn.Softmax(dim=-1)\n",
        "    self.model.to(device)\n",
        "    \n",
        "\n",
        "  def forward_prediction(self , input_ids):\n",
        "    x=self.model(input_ids=input_ids).logits\n",
        "    output=self.softmax_layer(x)\n",
        "    return(output)\n",
        "\n",
        "  \n",
        "  def forward_train(self , input_ids ):       \n",
        "    output=self.model(\n",
        "      input_ids=input_ids,\n",
        "    )   \n",
        "    return output\n",
        "\n",
        "  def disambiguation_train( self , input_ids , index_mask):\n",
        "    x=self.model(input_ids=input_ids).logits\n",
        "    output=torch.index_select(x,1,index_mask)\n",
        "    return output\n",
        "\n",
        "  def disambiguation_prediction(self , input_ids , index_mask):\n",
        "    x=self.model(input_ids=input_ids).logits\n",
        "    x=torch.index_select(x,1,index_mask)\n",
        "    output=self.softmax_layer(x)\n",
        "    return output \n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    return AdamW(self.parameters(),lr=0.00003) \n",
        "\n",
        "  def print(self):\n",
        "    print(\"MODEL CONFIG:\", self.model.config , \"MODEL STRUCTURE\" , self.model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wq1O8IKNIsT6"
      },
      "outputs": [],
      "source": [
        "def build_index_mask(input_ids,tokenizer = tokenizer):\n",
        "  par = tokenizer.decode(input_ids[0])\n",
        "  cut = par[6:len(par)-6] # need to remove the CLS and SEP added by the decoder [CLS] text [SEP]\n",
        "  index_mask = recognise_numbers(cut,tokenizer=tokenizer)\n",
        "  return index_mask.unsqueeze(0)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m26eRrFODDQs"
      },
      "outputs": [],
      "source": [
        "class storecsv(nn.Module):\n",
        "  def create(path_1):\n",
        "    headers = ['Status','Epoch','Loss','Accuracy','Accuracy per class','Macro F1','Precision','Recall']\n",
        "    # rows = [status,epoch,loss,acc,acc_in_class,f1,prec,rec]\n",
        "    with open(path_1, 'w') as f:\n",
        "      write = csv.writer(f,delimiter=',')\n",
        "      write.writerow(headers)\n",
        "  \n",
        "  def update(path_1,status,epoch,loss,acc,acc_in_class,f1,prec,rec):\n",
        "    row = [status,epoch,loss,acc,acc_in_class,f1,prec,rec]\n",
        "    with open(path_1, 'a') as f:\n",
        "      write = csv.writer(f)\n",
        "      write.writerow(row)\n",
        "\n",
        "\n",
        "  def create_pred(path_1):\n",
        "    headers = ['Paragraph','Prediction','True']\n",
        "    # rows = [status,epoch,loss,acc,acc_in_class,f1,prec,rec]\n",
        "    with open(path_1, 'w') as f:\n",
        "      write = csv.writer(f,delimiter=',')\n",
        "      write.writerow(headers)\n",
        "  \n",
        "  def update_pred(path_1,par,pred,true):\n",
        "    row = [par,pred,true]\n",
        "    with open(path_1, 'a') as f:\n",
        "      write = csv.writer(f)\n",
        "      write.writerow(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBFKdD4Je5nQ"
      },
      "outputs": [],
      "source": [
        "def reconstruct(outputs):\n",
        "  \"\"\"\n",
        "  receives an output from model.forward_predict (which has the probabilities)\n",
        "  outputs a list of same length with the categories reconstructed\"\"\"\n",
        "  out_categories = outputs\n",
        "  y_categories = []\n",
        "  listy = list(out_categories.size())\n",
        "  if len(listy)>1:\n",
        "    for i in range(listy[1]):\n",
        "      y_categories.append(labels_list[out_categories[0][i]])\n",
        "  else:\n",
        "    y_categories = []\n",
        "    \n",
        "  return y_categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avF4WA3OoP7a"
      },
      "outputs": [],
      "source": [
        "class Accuracy(nn.Module):\n",
        "  def reset(self):\n",
        "    self.num_correct = 0\n",
        "    self.num_examples = 0\n",
        "    self.fn = 0 # fn = Predicted H0 True H1 + Predict H1 True H0 ## predicted number / word but true is word / number\n",
        "    self.fp = 0 # fp = Predict H0 True H0 + C1 # predicted number but wrong class\n",
        "    self.tn = 0 # tn = Predict H1 True H1 # predicted word and it is word\n",
        "    self.tp = 0 # tp = Predict H0 True H0 + C0 category where cases are truly classified into the positive class #correctly predict number class\n",
        "    self.predicted_correctly = dict({1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0})\n",
        "    self.predicted_total = dict({1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0})\n",
        "    # H0: Number H1: Word\n",
        "    # C0: correct Class C1: wrong Class\n",
        "  \n",
        "  def update(self,y_pred,y_real):\n",
        "    y_pred = torch.argmax(y_pred, dim=-1)\n",
        "    subtraction = torch.subtract(y_pred,y_real)\n",
        "\n",
        "    self.num_correct += y_pred.shape[1]-torch.count_nonzero(subtraction) \n",
        "    self.num_examples += y_pred.shape[1]\n",
        "\n",
        "    for i in range(y_pred.shape[0]):\n",
        "      if (((y_real[0][i] != 0) and (y_pred[0][i] == 0)) or ((y_real[0][i] == 0) and (y_pred[0][i] != 0))): \n",
        "        self.fn += 1\n",
        "      elif ((y_real[0][i] != 0) and (y_pred[0][i] != 0) and (y_pred[0][i] != y_real[0][i])):\n",
        "        self.fp += 1\n",
        "      elif ((y_real[0][i] == 0) and (y_pred[0][i]) == 0):\n",
        "        self.tn +=1\n",
        "      elif ((y_real[0][i] != 0) and (y_pred[0][i]) == y_real[0][i]):\n",
        "        self.tp +=1\n",
        "      index = y_pred[0][i] \n",
        "      if ((y_pred[0][i] == y_real[0][i]) and (y_pred[0][i] != 0)):\n",
        "        self.predicted_correctly[index.item()] += 1   \n",
        "        self.predicted_total[index.item()] += 1\n",
        "      elif (y_pred[0][i] != 0):\n",
        "        self.predicted_total[index.item()] += 1\n",
        "      # print('fn',self.fn,'fp',self.fp,'tn',self.tn,'tp',self.tp)\n",
        "  def accuracy_global(self):\n",
        "    return self.num_correct/self.num_examples if self.num_examples else 0\n",
        "\n",
        "  def accuracy_in_class(self):\n",
        "    res = [0]\n",
        "    for class_num in range(1,9):\n",
        "      per_class = self.predicted_correctly[class_num]/self.predicted_total[class_num] if self.predicted_total[class_num] else -1 #when there is no occurance of the category\n",
        "      res.append(per_class)\n",
        "    return res\n",
        "\n",
        "  def precision(self):\n",
        "    return self.tp/(self.tp + self.fp) if self.tp + self.fp else 0\n",
        "    \n",
        "  def recall(self):\n",
        "    return self.tp/(self.tp + self.fn) if self.tp + self.fn else 0\n",
        "\n",
        "  def f1_score(self):\n",
        "    recall_f1 = self.recall()\n",
        "    precision_f1 = self.precision()\n",
        "    return 2*(recall_f1 * precision_f1) / (recall_f1 + precision_f1) if recall_f1 + precision_f1 else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8hwl_ZGM4rU"
      },
      "outputs": [],
      "source": [
        "def test_model( test_module , model , model_type):\n",
        "\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    test_loss=0\n",
        "    k=0\n",
        "    model.eval()\n",
        "    metric=Accuracy()\n",
        "    metric.reset()\n",
        "    storecsv.create_pred(path_test_pred)\n",
        "\n",
        "\n",
        "    if(model_type== 0): #RECOGNITION & DISAMBIGUATION CASE  \n",
        "      for batch in test_module:\n",
        "\n",
        "        input_ids=torch.squeeze(batch[\"input_ids\"])      \n",
        "        labels=torch.squeeze(batch[\"labels\"])\n",
        "\n",
        "        input_ids=input_ids.view(1,input_ids.shape[-1])\n",
        "        labels=labels.view(1,labels.shape[-1])\n",
        "\n",
        "        input_ids=input_ids.to(device)\n",
        "        labels=labels.to(device)\n",
        "\n",
        "        output=model.forward_train(input_ids).logits\n",
        "        probability_output=model.forward_prediction(input_ids)\n",
        "\n",
        "        loss_output=output.transpose(1,2)    \n",
        "        loss=loss_function(loss_output, labels)\n",
        "        test_loss+=loss.item()\n",
        "\n",
        "        par = tokenizer.decode(input_ids[0])\n",
        "\n",
        "        pred = reconstruct(torch.argmax(output, dim = -1))\n",
        "        true = reconstruct(labels)\n",
        "        storecsv.update_pred(path_test_pred,par[6:-6],pred,true)\n",
        "        metric.update(probability_output,labels)\n",
        "        \n",
        "        k=k+1\n",
        "\n",
        "      acc = metric.accuracy_global()\n",
        "      acc_in_class = metric.accuracy_in_class()\n",
        "      prec = metric.precision()\n",
        "      rec = metric.recall()\n",
        "      f1 = metric.f1_score()\n",
        "      test_loss = test_loss/k\n",
        "      print(f\"average loss --:{test_loss}\", f\"accuracy --:{acc}\",f\"accuracy class --:{acc_in_class}\",f\"f1_score --:{f1}\")\n",
        "\n",
        "\n",
        "    if(model_type== 1 ): #DISAMBIGUATION CASE\n",
        "      for batch in test_module:\n",
        "\n",
        "        input_ids=torch.squeeze(batch[\"input_ids\"])      \n",
        "        labels=torch.squeeze(batch[\"labels\"])\n",
        "        index_mask=batch[\"index_mask\"]\n",
        "        \n",
        "\n",
        "        input_ids=input_ids.view(1,input_ids.shape[-1])\n",
        "        labels=labels.view(1,labels.shape[-1])\n",
        "\n",
        "        input_ids=input_ids.to(device)\n",
        "        labels=labels.to(device)\n",
        "        index_mask=index_mask.to(device)\n",
        "\n",
        "        a , index_mask=torch.nonzero(index_mask, as_tuple=True)\n",
        "        labels=torch.index_select(labels,1,index_mask)\n",
        "\n",
        "        output=model.disambiguation_train(input_ids, index_mask=index_mask)\n",
        "        probability_output=model.disambiguation_prediction(input_ids , index_mask=index_mask)\n",
        "        loss_output=output.transpose(1,2)    \n",
        "        loss=loss_function(loss_output, labels)\n",
        "        test_loss+=loss.item()\n",
        "        metric.update(probability_output,labels)\n",
        "        par = tokenizer.decode(input_ids[0])\n",
        "        pred = reconstruct(torch.argmax(output, dim = -1))\n",
        "        true = reconstruct(labels)\n",
        "        storecsv.update_pred(path_test_pred,par[6:-6],pred,true)\n",
        "        \n",
        "        k=k+1\n",
        "      \n",
        "      acc = metric.accuracy_global()\n",
        "\n",
        "      acc_in_class = metric.accuracy_in_class()\n",
        "      prec = metric.precision())\n",
        "\n",
        "      rec = metric.recall()\n",
        "\n",
        "      f1 = metric.f1_score()\n",
        "\n",
        "      test_loss=test_loss/k\n",
        "      print(f\"test loss: {test_loss} \",f\"accuracy: {acc} \")\n",
        "\n",
        "    storecsv.update(path_test,'test',\"\",test_loss, acc, acc_in_class, f1, prec, rec)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X081tWw2Xr2E"
      },
      "outputs": [],
      "source": [
        "def disambiguation_training(data_module):\n",
        "  model=NERmodel()\n",
        "  model=model.to(device)\n",
        "  optimizer=model.configure_optimizers()\n",
        "  metric = Accuracy()\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "  storecsv.create(path_training)\n",
        "  storecsv.create(path_validation)\n",
        "\n",
        "  training_loss=[]\n",
        "  _validation_loss=[]\n",
        "  training_acc=[]\n",
        "  validation_acc=[]\n",
        "\n",
        "  training_acc_in_class=[]\n",
        "  validation_acc_in_class=[]\n",
        "\n",
        "  training_prec=[]\n",
        "  validation_prec=[]\n",
        "\n",
        "  training_rec=[]\n",
        "  validation_rec=[]\n",
        "\n",
        "  training_f1=[]\n",
        "  validation_f1=[]\n",
        "\n",
        "  training_acc_in_class=[]\n",
        "  validation_acc_in_class=[]\n",
        "\n",
        "  t0=time.time()\n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "  for i in range (NUM_EPOCHS):\n",
        "    print(f\"epoch--{i}\")\n",
        "    loss_count=0\n",
        "    metric.reset()\n",
        "    validation_loss=0\n",
        "    k=0\n",
        "    model.train()\n",
        "    for batch in data_module:\n",
        "      input_ids=torch.squeeze(batch[\"input_ids\"])      \n",
        "      labels=torch.squeeze(batch[\"labels\"])\n",
        "      index_mask=batch[\"index_mask\"]\n",
        "\n",
        "      input_ids=input_ids.view(1,input_ids.shape[-1])\n",
        "      labels=labels.view(1,labels.shape[-1])\n",
        "\n",
        "      index_mask=index_mask.to(device)\n",
        "      input_ids=input_ids.to(device)\n",
        "      labels=labels.to(device)\n",
        "\n",
        "      _a , index_mask=torch.nonzero(index_mask, as_tuple=True)\n",
        "\n",
        "      labels=torch.index_select(labels,1,index_mask).to(device)      \n",
        "\n",
        "      output=model.disambiguation_train(input_ids, index_mask=index_mask)\n",
        "      probability_output=model.disambiguation_prediction(input_ids , index_mask=index_mask)\n",
        "\n",
        "      loss_output=output.transpose(1,2)    \n",
        "      loss=loss_function(loss_output, labels)\n",
        "      loss_count+=loss.item()\n",
        "      loss=loss/accumulation_steps\n",
        "      loss.backward()\n",
        "      k+=1\n",
        "\n",
        "      metric.update(probability_output,labels)\n",
        "\n",
        "      if(k % accumulation_steps == 0):\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "      with torch.no_grad():\n",
        "\n",
        "        if(k % 20 ==0):\n",
        "          mean_loss=loss_count/20\n",
        "          training_loss.append(mean_loss)\n",
        "          loss_count=0\n",
        "\n",
        "          acc = metric.accuracy_global()\n",
        "          training_acc.append(acc)\n",
        "\n",
        "          acc_in_class = metric.accuracy_in_class()\n",
        "          training_acc_in_class.append(acc_in_class)\n",
        "\n",
        "          prec = metric.precision()\n",
        "          training_prec.append(prec)\n",
        "\n",
        "          rec = metric.recall()\n",
        "          training_rec.append(rec)\n",
        "\n",
        "          f1 = metric.f1_score()\n",
        "          training_f1.append(f1)\n",
        "\n",
        "          metric.reset()\n",
        "          print(f\"average loss --:{mean_loss}\", f\"accuracy --:{acc}\", f\"f1_score --:{f1}\",f\"accuracy class --:{acc_in_class}\")\n",
        "\n",
        "    storecsv.update(path_training,'training',i,mean_loss,acc,acc_in_class,f1,prec,rec)\n",
        "    k=0\n",
        "    model.eval()\n",
        "    for batch in validate_module:\n",
        "\n",
        "      input_ids=torch.squeeze(batch[\"input_ids\"])      \n",
        "      labels=torch.squeeze(batch[\"labels\"])\n",
        "      index_mask=batch[\"index_mask\"]\n",
        "      \n",
        "\n",
        "      input_ids=input_ids.view(1,input_ids.shape[-1])\n",
        "      labels=labels.view(1,labels.shape[-1])\n",
        "\n",
        "      input_ids=input_ids.to(device)\n",
        "      labels=labels.to(device)\n",
        "      index_mask=index_mask.to(device)\n",
        "\n",
        "      a , index_mask=torch.nonzero(index_mask, as_tuple=True)\n",
        "      labels=torch.index_select(labels,1,index_mask)\n",
        "\n",
        "      output=model.disambiguation_train(input_ids, index_mask=index_mask)\n",
        "      probability_output=model.disambiguation_prediction(input_ids , index_mask=index_mask)\n",
        "\n",
        "      loss_output=output.transpose(1,2)    \n",
        "      loss=loss_function(loss_output, labels)\n",
        "      validation_loss+=loss.item()\n",
        "      metric.update(probability_output,labels)\n",
        "      \n",
        "      k=k+1\n",
        "    \n",
        "    acc = metric.accuracy_global()\n",
        "    validation_acc.append(acc)\n",
        "\n",
        "    acc_in_class = metric.accuracy_in_class()\n",
        "    validation_acc_in_class.append(acc_in_class)\n",
        "\n",
        "    prec = metric.precision()\n",
        "    validation_prec.append(prec)\n",
        "\n",
        "    rec = metric.recall()\n",
        "    validation_rec.append(rec)\n",
        "\n",
        "    f1 = metric.f1_score()\n",
        "    validation_f1.append(f1)\n",
        "    \n",
        "    storecsv.update(path_validation,'validation',i,validation_loss,validation_acc,validation_acc_in_class,validation_f1,validation_prec,validation_rec)\n",
        "\n",
        "    metric.reset()\n",
        "\n",
        "    print(f\"validation loss: {validation_loss/k} \",f\"accuracy: {acc}\", f\"accuracy/class: {acc_in_class}\", f\"f1 score: {f1}\")\n",
        "\n",
        "  training_time=time.time()-t0\n",
        "  storecsv.update(path_training,'TIME TO TRAIN',training_time,mean_loss,acc,acc_in_class,f1,prec,rec)\n",
        "  print(\"training time:\", training_time)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zc3OWYOEpApp"
      },
      "outputs": [],
      "source": [
        "def recognition_training(data_module):\n",
        "  model=NERmodel()\n",
        "  model=model.to(device)\n",
        "  optimizer=model.configure_optimizers()\n",
        "  metric = Accuracy()\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "  storecsv.create(path_training)\n",
        "  storecsv.create(path_validation)\n",
        "\n",
        "  training_loss=[]\n",
        "  _validation_loss=[]\n",
        "  training_acc=[]\n",
        "  validation_acc=[]\n",
        "\n",
        "  training_acc_in_class=[]\n",
        "  validation_acc_in_class=[]\n",
        "\n",
        "  training_prec=[]\n",
        "  validation_prec=[]\n",
        "\n",
        "  training_rec=[]\n",
        "  validation_rec=[]\n",
        "\n",
        "  training_f1=[]\n",
        "  validation_f1=[]\n",
        "\n",
        "  training_acc_in_class=[]\n",
        "  validation_acc_in_class=[]\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  t0=time.time()\n",
        "\n",
        "  for i in range (NUM_EPOCHS):\n",
        "    print(f\"epoch--{i}\")\n",
        "    loss_count=0\n",
        "    metric.reset()\n",
        "    validation_loss=0\n",
        "    model.train()\n",
        "    k=0\n",
        "\n",
        "    for batch in data_module:\n",
        "\n",
        "      input_ids=torch.squeeze(batch[\"input_ids\"])      \n",
        "      labels=torch.squeeze(batch[\"labels\"])\n",
        "\n",
        "      input_ids=input_ids.view(1,input_ids.shape[-1])\n",
        "      labels=labels.view(1,labels.shape[-1])\n",
        "\n",
        "      input_ids=input_ids.to(device)\n",
        "      labels=labels.to(device)\n",
        "\n",
        "      output=model.forward_train(input_ids).logits\n",
        "      probability_output=model.forward_prediction(input_ids)\n",
        "\n",
        "\n",
        "      loss_output=output.transpose(1,2)    \n",
        "      loss=loss_function(loss_output, labels)\n",
        "      loss_count+=loss.item()\n",
        "      loss=loss/accumulation_steps\n",
        "      loss.backward()\n",
        "      k+=1\n",
        "\n",
        "      metric.update(probability_output,labels)\n",
        "\n",
        "      if(k % accumulation_steps == 0):\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "      with torch.no_grad():\n",
        "\n",
        "        if(k % 20 == 0): # TO DO CHECK WITH CLEMENTE IF 20 SHOULD BE REPLACED BY ACCUMULATION STEP\n",
        "          mean_loss=loss_count/20\n",
        "          training_loss.append(mean_loss)\n",
        "          loss_count=0\n",
        "\n",
        "          acc = metric.accuracy_global()\n",
        "          training_acc.append(acc)\n",
        "\n",
        "          acc_in_class = metric.accuracy_in_class()\n",
        "          training_acc_in_class.append(acc_in_class)\n",
        "\n",
        "          prec = metric.precision()\n",
        "          training_prec.append(prec)\n",
        "\n",
        "          rec = metric.recall()\n",
        "          training_rec.append(rec)\n",
        "\n",
        "          f1 = metric.f1_score()\n",
        "          training_f1.append(f1)\n",
        "          metric.reset()\n",
        "\n",
        "\n",
        "          print(f\"average loss --:{mean_loss}\", f\"accuracy --:{acc}\" ,f\"accuracy class --:{acc_in_class}\",f\"f1_score --:{f1}\")\n",
        "\n",
        "          \n",
        "    \n",
        "    k=0\n",
        "    storecsv.update(path_training,'training',i,mean_loss,acc,acc_in_class,f1,prec,rec)\n",
        "\n",
        "    model.eval()\n",
        "    for batch in validate_module:\n",
        "\n",
        "      input_ids=torch.squeeze(batch[\"input_ids\"])      \n",
        "      labels=torch.squeeze(batch[\"labels\"])\n",
        "\n",
        "      input_ids=input_ids.view(1,input_ids.shape[-1])\n",
        "      labels=labels.view(1,labels.shape[-1])\n",
        "\n",
        "      input_ids=input_ids.to(device)\n",
        "      labels=labels.to(device)\n",
        "\n",
        "      output=model.forward_train(input_ids).logits\n",
        "      probability_output=model.forward_prediction(input_ids)\n",
        "\n",
        "      loss_output=output.transpose(1,2)    \n",
        "      loss=loss_function(loss_output, labels)\n",
        "      validation_loss+=loss.item()\n",
        "\n",
        "      metric.update(probability_output,labels)\n",
        "      \n",
        "      k=k+1\n",
        "\n",
        "    acc = metric.accuracy_global()\n",
        "    validation_acc.append(acc)\n",
        "\n",
        "    prec = metric.precision()\n",
        "    validation_prec.append(prec)\n",
        "\n",
        "    rec = metric.recall()\n",
        "    validation_rec.append(rec)\n",
        "\n",
        "    f1 = metric.f1_score()\n",
        "    validation_f1.append(f1)\n",
        "\n",
        "    acc_in_class = metric.accuracy_in_class()\n",
        "    validation_acc_in_class.append(acc_in_class)\n",
        "\n",
        "    metric.reset()\n",
        "\n",
        "    print(f\"validation loss: {validation_loss/k} \",f\"accuracy: {acc} \", f\"accuracy/class: {acc_in_class} \",f\"f1_score --:{f1}\")\n",
        "    storecsv.update(path_validation,'validation',i,mean_loss,acc,acc_in_class,f1,prec,rec)\n",
        "\n",
        "  trainingtime=time.time()-t0\n",
        "  storecsv.update(path_training,'TIME TO TRAIN',trainingtime,mean_loss,acc,acc_in_class,f1,prec,rec)\n",
        "  print(\"trainingtime:\", trainingtime)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ppZW0WLsMIU1"
      },
      "outputs": [],
      "source": [
        "train_dataset=NERDataset(train_list,tokenizer,)\n",
        "validate_dataset=NERDataset(validate_list,tokenizer)\n",
        "test_dataset=NERDataset(test_list, tokenizer)\n",
        "\n",
        "train_module = DataLoader(train_dataset, batch_size=1,shuffle=\"True\") #droplast=\"True\"\n",
        "validate_module = DataLoader(validate_dataset, batch_size=1 , shuffle=\"True\" )\n",
        "test_module= DataLoader(test_dataset , batch_size=1 , shuffle=\"True\" )\n",
        "\n",
        "path_training ='/content/training_D_15_final.csv' #UPDATE_PATH : training_model_epochs_lr_accumulation_dataset_model_name\n",
        "path_validation = '/content/vallidation__D_final.csv' #UPDATE_PATH : validation_model_epochs_lr_accumulation_dataset_model_name \n",
        "path_test='/content/test_D__final.csv' #UPDATE_PATH : test_model_epochs_lr_accumulation_dataset_model_name\n",
        "path_test_pred='/content/test_prediction__final_FFFF.csv' #UPDATE_PATH : test_model_epochs_lr_accumulation_dataset_model_name\n",
        "#model can be D for disambiguation or RD for recognition and disambiguation\n",
        "\n",
        "# Disambiguation\n",
        "model=disambiguation_training(train_module)\n",
        "torch.save(model.state_dict(), '/content/model_D_weights')\n",
        "test_model( test_module , model , model_type=1) # 1 FOR DISAMBIGUATION , 0 FOR RECOGNITION &DISAMBIGUATION\n",
        "\n",
        "#Recognition\n",
        "# model=recognition_training(train_module)\n",
        "# torch.save(model.state_dict(), '/content/model_RD_weights')\n",
        "# test_model( test_module , model , model_type=0) # 1 FOR DISAMBIGUATION , 0 FOR RECOGNITION &DISAMBIGUATION"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "BERT_NER_Torch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}